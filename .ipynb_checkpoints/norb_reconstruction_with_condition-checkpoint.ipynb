{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f357f6-4f03-496f-9a85-5e3d9e68ba94",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "### Standard modules\n",
    "* datetime: [Basic date and time types.](https://docs.python.org/3/library/datetime.html)\n",
    "* glob: [Unix style pathname pattern expansion.](https://docs.python.org/3/library/glob.html?highlight=glob#module-glob)\n",
    "* gzip: [This module provides a simple interface to compress and decompress files.](https://docs.python.org/3/library/gzip.html)\n",
    "* math: [Mathematical functions.](https://docs.python.org/3/library/math.html)\n",
    "* os: [Miscellaneous operating system interfaces.](https://docs.python.org/3/library/os.html?highlight=os#module-os)\n",
    "* random: [Generate pseudo-random numbers.](https://docs.python.org/3/library/random.html?highlight=random#module-random)\n",
    "* shutil: [Offers a number of high-level operations on files and collections of files.](https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil)\n",
    "* struct: [Interpret bytes as packed binary data.](https://docs.python.org/3/library/struct.html?highlight=struct#module-struct)\n",
    "\n",
    "### Jupyter notebook modules\n",
    "* jupyter: [Coding framework.](https://docs.jupyter.org/en/latest/)\n",
    "* IPython: [IPython provides a rich toolkit to help you make the most of using Python interactively.](https://ipython.readthedocs.io/en/stable/)\n",
    "* ipywidgets: [Jupyter Widgets are interactive browser controls for Jupyter notebooks.](https://ipywidgets.readthedocs.io/en/latest/)\n",
    "\n",
    "### Additional packages\n",
    "* imageio: [Provides an easy interface to read and write a wide range of image data.](https://imageio.readthedocs.io/en/stable/)\n",
    "* matplotlib: [Library for creating static, animated, and interactive visualizations.](https://matplotlib.org/stable/users/index)\n",
    "* numpy: [Library that provides a multidimensional array object, various derived objects, and an assortment of routines for fast operations on arrays.](https://numpy.org/doc/stable/)\n",
    "* torch: [An optimized tensor library for deep learning using GPUs and CPUs.](https://pytorch.org/docs/stable/index.html)\n",
    "* torchvision: [Package consists of popular datasets, model architectures, and common image transformations for computer vision.](https://pytorch.org/vision/stable/index.html)\n",
    "* tqdm : [Adds a smart progress meter to loops.](https://tqdm.github.io/)\n",
    "* wget: [Package for downloading files from web addresses.](https://pypi.org/project/wget/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages.\n",
    "!pip install -qq imageio matplotlib numpy torch torchvision tqdm wget jupyter ipywidgets==7.4.2\n",
    "\n",
    "# Import python standard modules.\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import gzip\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import struct\n",
    "\n",
    "# Jupyter notebook modules.\n",
    "from IPython.display import Image\n",
    "\n",
    "# Import the installed packages. \n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import wget\n",
    "\n",
    "print('Finished importing the packages.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18854578-88e0-43c9-b4ae-87dfbccdde5e",
   "metadata": {},
   "source": [
    "## Define arguments\n",
    "### DATA_*\n",
    "Arguments for loading the data.\n",
    "* DATA_FILE_TYPES: The file extensions of the norb dataset.\n",
    "* DATA_FOLDER: The folder where the data files are stored.\n",
    "* DATA_PREFIXES: The file prefix of the norb file names.\n",
    "* DATA_NUMBERS_FOR_MAPPING_DATA_TYPES: The magic number encodes the element type of the matrix. Note: Those are only the numbers needed for the files in this project.\n",
    "* DATA_URL: Url for downloading the data files.\n",
    "\n",
    "### PREP_*\n",
    "Arguments for preparing the data.\n",
    "* PREP_BATCH_SIZE: Defines how many files are processed at each step.\n",
    "* PREP_CAMERA: Index of the camera (channel of the image).\n",
    "* PREP_IMAGE_SIZE: The pixel size of the images.\n",
    "* PREP_SHUFFLE_DATA: If true, the data is shuffled.\n",
    "\n",
    "### RUN_*\n",
    "Arguments for defining and running the neural network.\n",
    "* RUN_CRITIC_REPEAT: Defines how often the critic is used in each step.\n",
    "* RUN_DEVICE: Which device to use for running the network (CUDA or CPU).\n",
    "* RUN_DISPLAY_EACH: Show images, each n steps.\n",
    "* RUN_DROPOUT_VALUE: Probability of an element to be zeroed.\n",
    "* RUN_EPOCHS: Defines how often the training is repeated for all data.\n",
    "* RUN_HIDDEN_DIM: The ground value for the dimensions in the hidden layers.\n",
    "* RUN_LABEL_CHANNELS: The total number of classes for labeling the data set.\n",
    "* RUN_LEAK_VALUE: Controls the angle of the negative slope of the leakyRelu function.\n",
    "* RUN_OPT_BETA_1: Parameter for the Adam optimizer. The exponential decay rate for the first-moment estimates.\n",
    "* RUN_OPT_BETA_2: Parameter for the Adam optimizer. The exponential decay rate for the second-moment estimates.\n",
    "* RUN_OPT_LR: Weight of the gradient penalty\n",
    "* RUN_TEST_LABELS: Label classes for creating a specific test noise.\n",
    "* RUN_Z_DIM: Defines how many channels the noise tensor has.\n",
    "\n",
    "### RES_*\n",
    "Arguments for showing the results.\n",
    "* RES_GIF_FILE: Name and path for storing the GIF file, containing the result data.\n",
    "* RES_IMAGE_AMOUNT: How many images to show.\n",
    "* RES_IMAGE_FOLDER: Folder for generated test images, inside the output folder.\n",
    "* RES_LOSS_DATA_CRIT: File for storing the critic's loss values.\n",
    "* RES_LOSS_DATA_GEN: File for storing the generator loss values.\n",
    "* RES_LOSS_DATA_TEST: File for storing the test loss values.\n",
    "* RES_LOSS_PLOT_TEST: File for storing the test loss plot. \n",
    "* RES_LOSS_PLOT_TRAIN: File for storing the training loss plot. \n",
    "* RES_MODEL_PATH: Path for storing the models.\n",
    "* RES_OUTPUT_FOLDER: Folder for this runs results.\n",
    "* RES_PLOT_COLUMNS: The amount of images in one row of the plot.\n",
    "* RES_PLOT_SIZE: The size of the plots width and height in inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e96882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables.\n",
    "DATA_FILE_TYPES = ['info', 'cat', 'dat']\n",
    "DATA_FOLDER = \"./data/\"\n",
    "DATA_PREFIXES = {\n",
    "    'train': 'smallnorb-5x46789x9x18x6x2x96x96-training-',\n",
    "    'test': 'smallnorb-5x01235x9x18x6x2x96x96-testing-',\n",
    "}\n",
    "DATA_NUMBERS_FOR_MAPPING_DATA_TYPES = {\n",
    "    '1e3d4c55': np.uint8,\n",
    "    '1e3d4c54': np.int32,\n",
    "}\n",
    "DATA_URL = 'https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/'\n",
    "\n",
    "PREP_BATCH_SIZE = 32\n",
    "PREP_CAMERA = 0\n",
    "PREP_IMAGE_SIZE = 67\n",
    "PREP_SHUFFLE_DATA = True\n",
    "\n",
    "RUN_CRITIC_REPEAT = 3\n",
    "RUN_CRITIC_LAMBDA = 10.0\n",
    "RUN_DEVICE = 'cuda'\n",
    "RUN_DISPLAY_EACH = 1\n",
    "RUN_DROPOUT_VALUE = 0.1\n",
    "RUN_EPOCHS = 100\n",
    "RUN_HIDDEN_DIM = 32\n",
    "RUN_LABEL_CHANNELS = [5, 10, 9, 18, 6] # (5 categories, 10 instances, 9 elevations, and 18 azimuths, 6 lightings)\n",
    "RUN_LEAK_VALUE = 0.1\n",
    "RUN_OPT_BETA_1 = 0.9\n",
    "RUN_OPT_BETA_2 = 0.999\n",
    "RUN_OPT_LR = 0.001\n",
    "RUN_TEST_LABELS = torch.as_tensor([2, 6, 7, 17, 0], dtype=torch.int64)\n",
    "RUN_Z_DIM = 100\n",
    "\n",
    "RES_GIF_FILE = 'norb_test_images.gif'\n",
    "RES_IMAGE_AMOUNT = 9\n",
    "RES_IMAGE_FOLDER = './img'\n",
    "RES_LOSS_DATA_CRIT = 'norb_loss_crit.txt'\n",
    "RES_LOSS_DATA_GEN = 'norb_loss_gen.txt'\n",
    "RES_LOSS_DATA_TEST = 'norb_loss_test.txt'\n",
    "RES_LOSS_PLOT_TEST = 'norb_loss_plot_test.png'\n",
    "RES_LOSS_PLOT_TRAIN = 'norb_loss_plot_train.png'\n",
    "RES_MODEL_PATH = './'\n",
    "RES_OUTPUT_FOLDER = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "RES_PLOT_COLUMNS = 5\n",
    "RES_PLOT_SIZE = 21\n",
    "\n",
    "print('Finished setting the arguments.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2d3d0-7c35-4138-be9d-bd0bda889bab",
   "metadata": {},
   "source": [
    "## Load files\n",
    "### Description\n",
    "Download the files and convert the binary data to tensor objects. Afterwards, show some examples.\n",
    "\n",
    "### Functions\n",
    "* download_and_unzip: Downloads and unzips a file.\n",
    "* get_int_from_file: Helper function for reading int from binary file.\n",
    "* load_norb_data: Load the norb data from binary files and convert it to images.\n",
    "* show_tensor_images: Shows images using pyplot from the matplotlib package. Also prints some information about the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ddd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(file_name: str, file_extension: str, dst_folder: str, url: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads and unzips a file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name: str\n",
    "         The basename of the compressed file (without the extension for the compressed version).\n",
    "    file_extension: str\n",
    "        The file extension for the compressed version.\n",
    "    dst_folder: str\n",
    "        Destination folder for the files.\n",
    "    url: str\n",
    "        Source URL for the file, without the filename.\n",
    "    \"\"\"\n",
    "    # Build file and zip path.\n",
    "    file_path = os.path.join(dst_folder, file_name)\n",
    "    gz_name = file_name + '.gz'\n",
    "\n",
    "    # Check if the data folder already exists, if not create the folder.\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.mkdir(dst_folder)\n",
    "\n",
    "    # Check if this file already exists.\n",
    "    if not os.path.exists(file_path):\n",
    "        # Download the file.\n",
    "        wget.download(url + gz_name , gz_name)\n",
    "\n",
    "        # Decompress the file and move it to the folder.\n",
    "        with gzip.open(gz_name, 'rb') as f_in:\n",
    "            with open(file_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        # Delete the compressed version afterwards.\n",
    "        os.remove(gz_name)\n",
    "\n",
    "def get_int_from_file(f: object) -> int:\n",
    "    \"\"\"\n",
    "    Helper function for reading int from binary file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: file-object\n",
    "        The data file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The content of the file as integer.\n",
    "    \"\"\"\n",
    "    num, = struct.unpack('i', f.read(4))\n",
    "    return num\n",
    "\n",
    "\n",
    "def load_norb_data(file_folder: str, file_prefix: object, file_types: list, map_data_types: object) -> object: \n",
    "    \"\"\"\n",
    "    Load the norb data from binary files and convert it to images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_folder: str\n",
    "        The folder where the data files are stored.\n",
    "    file_prefix: object of str\n",
    "        The file prefix of the norb file names.\n",
    "    file_types: list of str\n",
    "        The file extensions of the norb dataset.\n",
    "    map_data_types: object of numpy.dtype\n",
    "        The magic number encodes the element type of the matrix.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    object\n",
    "        Images of the norb dataset.\n",
    "    \"\"\"\n",
    "    # Define the return object.\n",
    "    loaded_data = {}\n",
    "    \n",
    "    # Loop over each file.\n",
    "    for dataset, prefix in file_prefix.items():\n",
    "        for filetype in file_types:\n",
    "            # Set up the file name and path for reading the files.\n",
    "            filename = prefix + filetype + \".mat\"\n",
    "            file_loc = os.path.join(file_folder, filename)\n",
    "\n",
    "            with open( file_loc, 'rb') as f:\n",
    "                # Read the magic_num, convert it to hexadecimal and look up the data_type.\n",
    "                raw_magic_num = get_int_from_file(f)\n",
    "                magic_num = format(raw_magic_num, '02x')\n",
    "                data_type = map_data_types[magic_num]\n",
    "\n",
    "                # Read how many dimensions to expect.\n",
    "                ndim = get_int_from_file(f)\n",
    "\n",
    "                # Read at least 3 ints, or however many ndim there are.\n",
    "                shape = [\n",
    "                    get_int_from_file(f)\n",
    "                    for i in range(max(ndim, 3))\n",
    "                ]   \n",
    "\n",
    "                # But in case ndims < 3, take at most n_dim elements.\n",
    "                shape = shape[:ndim]\n",
    "\n",
    "                # Now load the actual data.\n",
    "                loaded_data[(dataset, filetype)] = np.fromfile(\n",
    "                    f, \n",
    "                    dtype=data_type, \n",
    "                    count=np.prod(shape)\n",
    "                ).reshape(shape)\n",
    "    \n",
    "    return loaded_data        \n",
    "\n",
    "\n",
    "def show_tensor_images(image: np.array, infos: list, columns: int, size: int, channel: int =-1, file_path: str ='') -> None:\n",
    "    \"\"\"\n",
    "    Shows images using pyplot from the matplotlib package. Also prints some information about the images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.array\n",
    "        The image numpy array.\n",
    "    infos: list of str\n",
    "        Contains some information about the images.\n",
    "    columns: int\n",
    "        The amount of columns for the plot\n",
    "    size: int\n",
    "        The size of the plots width and height in inches.\n",
    "    channel: int, optional\n",
    "        If -1 all channels are shown as RGB image. If not -1 only this specific channel is shown as a grayscale image.\n",
    "    file_path: str, optional\n",
    "        If '' the plots are not saved as GIF. If not '' the content of file_path is used to save the images as PNG.\n",
    "    \"\"\"\n",
    "    # Get the image amount and define the amount of rows for the plot.\n",
    "    image_length = len(image)\n",
    "    rows = math.ceil(image_length / columns)\n",
    "    \n",
    "    # Set the size for each image in the plot.\n",
    "    fig = plt.figure(figsize=(size,size)) \n",
    "    \n",
    "    # Loop over each image and add it to the plot.\n",
    "    for i in range(0, image_length):\n",
    "        plt.subplot(rows, columns, i+1)\n",
    "        \n",
    "        if channel == -1:\n",
    "            plt.imshow(images[i], cmap=\"rgb\")\n",
    "        else:\n",
    "            plt.imshow(image[i][channel], cmap=\"gray\")\n",
    "            \n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Save the file, if file_path is set.\n",
    "    if file_path != '':\n",
    "        plt.savefig('{}.png'.format(file_path))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print the content of the info list.\n",
    "    for j in range(0, len(infos)):\n",
    "        print(f'{j+1}: {infos[j]}')\n",
    "\n",
    "\n",
    "# Loop over each file prefix and file type and download the files.\n",
    "for prefix in DATA_PREFIXES:\n",
    "    for t in DATA_FILE_TYPES:   \n",
    "        download_and_unzip(DATA_PREFIXES[prefix] + t + '.mat', '.gz', DATA_FOLDER, DATA_URL)\n",
    "                \n",
    "# Load the data files.\n",
    "loaded_data = load_norb_data(DATA_FOLDER, DATA_PREFIXES, DATA_FILE_TYPES, DATA_NUMBERS_FOR_MAPPING_DATA_TYPES)\n",
    "\n",
    "# Show some random original images.\n",
    "idx = np.random.randint( loaded_data[('train', 'cat')].shape[0], size=RES_IMAGE_AMOUNT)\n",
    "\n",
    "# Collect the information from the files to show some examples.\n",
    "infos = []\n",
    "images = []\n",
    "for i in idx:\n",
    "    # Get the information from the cat file.\n",
    "    info_text = str(loaded_data[('train', 'cat')][i]) + ' ' + str(loaded_data[('train', 'info')][i])\n",
    "    infos.append(info_text)\n",
    "    \n",
    "    # Get the image data from the dat file.\n",
    "    images.append(loaded_data[('train', 'dat')][i])\n",
    "    \n",
    "# Show image.\n",
    "show_tensor_images(np.array(images), infos, RES_PLOT_COLUMNS, RES_PLOT_SIZE, 0, '')\n",
    "\n",
    "print('Finished loading files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcba63-a0f5-41ca-9b88-be6b35efd639",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "### Description\n",
    "Here the data are prepared (normalization, resizing etc.) and a data loader is created, that can be used for training the model.\n",
    "\n",
    "### Transformation steps\n",
    "* Selecting a specific camera (tensor channel).\n",
    "* Converting the tensor values from a range of 0 to 255 to a range of 0 to 1.\n",
    "* Insure that all images have the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc61166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categories_tensor_values(tensor: torch.Tensor, index: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Gets the a distinct sorted list of all values in a tensor.\n",
    "    Afterwards the values in the tensor are replaced with the corresponding position of this value in the sorted list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor: torch.Tensor\n",
    "        The input tensor object.\n",
    "    index: int\n",
    "        The index for dimension 1. Only values in this specific position are replaced.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The tensor object, with the changed values.\n",
    "    \"\"\"\n",
    "    # Get the unique value list.\n",
    "    categories = torch.unique(tensor[:, index])\n",
    "    \n",
    "    # Loop over the category list and dimension 0 of the input tensor.\n",
    "    for i in range(0, len(categories)):\n",
    "        for j in range(0, len(tensor[:, index])):\n",
    "            # Check if the value in the category list matches with the value in the tensor.\n",
    "            # If so, replace the value in the tensor with the index from the category list.\n",
    "            if tensor[j, index] == categories[i]:\n",
    "                tensor[j, index] = i\n",
    "    return tensor\n",
    "\n",
    "# Load the content of the dat files.\n",
    "images_train = torch.from_numpy(loaded_data[('train', 'dat')])\n",
    "images_test  = torch.from_numpy(loaded_data[('test', 'dat')])\n",
    "\n",
    "# Load the content of the cat files.\n",
    "category_train = torch.from_numpy(loaded_data[('train', 'cat')])\n",
    "category_test  = torch.from_numpy(loaded_data[('test', 'cat')])\n",
    "\n",
    "# Load the content of the cat files.\n",
    "info_train = torch.from_numpy(loaded_data[('train', 'info')])\n",
    "info_test  = torch.from_numpy(loaded_data[('test', 'info')])\n",
    "\n",
    "# Join the categories and information to a combined label tensor.\n",
    "labels_train = torch.cat([category_train.view(len(category_train), 1), info_train], dim=1).to(torch.int64)\n",
    "labels_test = torch.cat([category_test.view(len(category_test), 1), info_test], dim=1).to(torch.int64)\n",
    "\n",
    "# Categories the azimuth values.\n",
    "labels_train = categories_tensor_values(labels_train, 3)\n",
    "labels_test = categories_tensor_values(labels_test, 3)\n",
    "\n",
    "# Define transformation for the data.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x[PREP_CAMERA]),\n",
    "    transforms.Lambda(lambda x: x / 255),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(PREP_IMAGE_SIZE),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Transform the training data.\n",
    "data_train = torch.empty([images_train.size(0), 1, PREP_IMAGE_SIZE, PREP_IMAGE_SIZE])\n",
    "for i in range(0, images_train.size(0)):\n",
    "    data_train[i] = transform(images_train[i])\n",
    "\n",
    "# Transform the test data.\n",
    "data_test = torch.empty([images_test.size(0), 1, PREP_IMAGE_SIZE, PREP_IMAGE_SIZE])\n",
    "for i in range(0, images_test.size(0)):\n",
    "    data_test[i] = transform(images_test[i])\n",
    "    \n",
    "# Create data sets for training and test files.\n",
    "data_train = torch.utils.data.TensorDataset(data_train, labels_train)\n",
    "data_test = torch.utils.data.TensorDataset(data_test, labels_test)\n",
    "\n",
    "# Merge both datasets.\n",
    "merged_data = torch.utils.data.ConcatDataset([data_train, data_test])\n",
    "\n",
    "# Get image from test label.\n",
    "test_image = []\n",
    "for image, label in merged_data:\n",
    "    if torch.equal(label, RUN_TEST_LABELS):\n",
    "        test_image.append(image.numpy())\n",
    "\n",
    "# Create a data loader for the data.\n",
    "loader_train = torch.utils.data.DataLoader(merged_data, batch_size=PREP_BATCH_SIZE, shuffle=PREP_SHUFFLE_DATA)\n",
    "\n",
    "# Show some random prepared images.\n",
    "idx = np.random.randint( len(merged_data), size=RES_IMAGE_AMOUNT)\n",
    "\n",
    "images = []\n",
    "for i in idx:\n",
    "    # Get the image data from the dat file.\n",
    "    images.append((merged_data[i][0]).numpy())\n",
    "\n",
    "# Show image.\n",
    "images = np.array(images)\n",
    "images = images * 255\n",
    "show_tensor_images(images, [], RES_PLOT_COLUMNS, RES_PLOT_SIZE, 0, '')\n",
    "\n",
    "print('Finished preparing the data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48a584-84e5-43e6-94f5-473677f128b8",
   "metadata": {},
   "source": [
    "## Define the network\n",
    "### Description\n",
    "Defines a function for creating the noise vector and the classes for the generator and the critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_samples: int, z_dim: int, device: str ='cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create a noise vector with dimensions (n_samples, z_dim)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples: int\n",
    "        The amount of samples.\n",
    "    z_dim: int\n",
    "        The amount of dimensions/channels.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.tensor\n",
    "        Noise vector.\n",
    "    \"\"\"\n",
    "    return torch.randn(n_samples, z_dim, device=device)\n",
    "\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    \"\"\" \n",
    "    The generator class for producing fake images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z_dim: int\n",
    "        The dimensions/channels of the noise vector.\n",
    "    hidden_dim: int\n",
    "        The ground value for the dimensions in the hidden layers.\n",
    "    dropout_value: float, optional\n",
    "        The probability of an element to be zeroed.\n",
    "    leak_value: float, optional\n",
    "        Controls the angle of the negative slope.\n",
    "    \"\"\"\n",
    "    def __init__(self, z_dim: int, hidden_dim: int, dropout_value: float =0.5, leak_value: float = 0.01) -> None:\n",
    "        \"\"\"\n",
    "        Initialization function for the generator. \n",
    "        Defines how many network blocks are used and which are used for each block.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(\n",
    "            self.convTranspose2d_block(z_dim, hidden_dim, 3, 1, dropout_value, leak_value),\n",
    "            self.convTranspose2d_block(hidden_dim, hidden_dim, 3, 2, dropout_value, leak_value),\n",
    "            self.convTranspose2d_block(hidden_dim, hidden_dim, 5, 1, dropout_value, leak_value),\n",
    "            self.convTranspose2d_block(hidden_dim, hidden_dim, 5, 2, dropout_value, leak_value),\n",
    "            self.convTranspose2d_block(hidden_dim, hidden_dim, 7, 1, dropout_value, leak_value),\n",
    "            self.convTranspose2d_block(hidden_dim, 1, 7, 2, dropout_value, leak_value, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def convTranspose2d_block(self, input_channels: int, output_channels: int, \n",
    "                  kernel_size: int, stride: int, dropout_value: float, \n",
    "                  leak_value: float, final_layer: bool =False) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Implements a set of layers of the network. The main part of this block is the ConvTranspose2d layer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_channels: int\n",
    "            Number of channels in the input image.\n",
    "        output_channels: int\n",
    "            Number of channels produced by the convolution.\n",
    "        kernel_size: int\n",
    "            The size of the filters that are used.\n",
    "        stride: int\n",
    "            The amount of steps taken, moving from one frame to another the next frame.\n",
    "        dropout_value: float\n",
    "            The probability of an element to be zeroed.\n",
    "        leak_value: float\n",
    "            Controls the angle of the negative slope.\n",
    "        final_layer: bool\n",
    "            Flag for differentiating between the final layer and all other layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.nn.Sequential\n",
    "            A combination of different layers for the generator.\n",
    "        \"\"\"\n",
    "        if not final_layer:\n",
    "            # Define the block for not final layer.\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                torch.nn.InstanceNorm2d(output_channels),\n",
    "                torch.nn.LeakyReLU(leak_value, inplace=True),\n",
    "                torch.nn.Dropout(dropout_value)\n",
    "            )\n",
    "        else:\n",
    "            # Define the block for the final layer.\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                torch.nn.InstanceNorm2d(output_channels),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "        \n",
    "    def forward(self, noise: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Function for completing a forward pass of the generator.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        noise: torch.Tensor\n",
    "            A noise vector.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            An image.\n",
    "        \"\"\"\n",
    "        x = noise.view(noise.size(0), noise.size(1), 1, 1)        \n",
    "        x = self.layers(x)       \n",
    "        return x\n",
    "\n",
    "\n",
    "class Critic(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The critic class defining how real a fake image is.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_channel: int\n",
    "        The channels of the image.\n",
    "    hidden_dim: int\n",
    "        The ground value for the dimensions in the hidden layers.\n",
    "    dropout_value: float, optional\n",
    "        The probability of an element to be zeroed.\n",
    "    leak_value: float, optional\n",
    "        Controls the angle of the negative slope.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, img_channel: int, hidden_dim: int, dropout_value: float =0.5, leak_value: float = 0.01) -> None:\n",
    "        super(Critic, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialization function for the critic. \n",
    "        Defines how many network blocks are used and which are used for each block.\n",
    "        \"\"\"\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            self.conv2d_block(img_channel, hidden_dim, 7, 2, dropout_value, leak_value),\n",
    "            self.conv2d_block(hidden_dim, hidden_dim, 7, 1, dropout_value, leak_value),\n",
    "            self.conv2d_block(hidden_dim, hidden_dim, 5, 2, dropout_value, leak_value),\n",
    "            self.conv2d_block(hidden_dim, hidden_dim, 5, 1, dropout_value, leak_value),\n",
    "            self.conv2d_block(hidden_dim, hidden_dim, 3, 2, dropout_value, leak_value),\n",
    "            self.conv2d_block(hidden_dim, 1, 3, 1, dropout_value, leak_value, final_layer=True)\n",
    "        )\n",
    "        \n",
    "    def conv2d_block(self, input_channels: int, output_channels: int,\n",
    "                   kernel_size: int, stride: int, dropout_value: float,\n",
    "                   leak_value: float, final_layer: bool =False) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Implements a set of layers of the network. The main part of this block is the Conv2d layer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_channels: int\n",
    "            Number of channels in the input image.\n",
    "        output_channels: int\n",
    "            Number of channels produced by the convolution.\n",
    "        kernel_size: int\n",
    "            The size of the filters that are used.\n",
    "        stride: int\n",
    "            The amount of steps taken, moving from one frame to another the next frame.\n",
    "        dropout_value: float\n",
    "            The probability of an element to be zeroed.\n",
    "        leak_value: float\n",
    "            Controls the angle of the negative slope.\n",
    "        final_layer: bool\n",
    "            Flag for differentiating between the final layer and all other layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.nn.Sequential\n",
    "            A combination of different layers for the generator.\n",
    "        \"\"\"\n",
    "        if not final_layer:\n",
    "            # Define the block for not final layer.\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                torch.nn.InstanceNorm2d(output_channels),\n",
    "                torch.nn.LeakyReLU(leak_value, inplace=True),\n",
    "                torch.nn.Dropout(dropout_value)\n",
    "            )\n",
    "        else:\n",
    "            # Define the block for the final layer.\n",
    "            return torch.nn.Sequential( \n",
    "                torch.nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "            )\n",
    "        \n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Function for completing a forward pass of the critic.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image: torch.Tensor\n",
    "            An image tensor with dimension (im_chan).\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            A 1-dimension tensor representing fake/real.\n",
    "        \"\"\"       \n",
    "        x = self.layers(image)    \n",
    "        return x.view(len(x), -1)\n",
    "\n",
    "\n",
    "print('Finished defining noise function, generator and critic.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95b1ee-ded8-43d1-b2e2-7b3fb6c531e5",
   "metadata": {},
   "source": [
    "## Gradient Penalty\n",
    "### Description\n",
    "This part contains functions for calculating the gradient penalty.\n",
    "### Functions\n",
    "* get_gradient: Return the gradient of the critic scores with respect to mixes of real and fake images.\n",
    "* gradient_penalty: Return the gradient penalty, given a gradient. Given a batch of image gradients, you calculate the magnitude of each image's gradient and penalize the mean quadratic distance of each magnitude to 1.\n",
    "* get_gen_loss: Return the loss of a generator given the critic scores of the generator's fake images.\n",
    "* get_crit_loss: Return the loss of a critic given the critic scores for fake and real images, the gradient penalty, and gradient penalty weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee1ad2-dbc4-4319-9c91-6c57a9316cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(crit: Critic, real: torch.Tensor, fake: torch.Tensor, epsilon: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the gradient of the critic scores with respect to mixes of real and fake images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        crit: Critic\n",
    "            The critic model.\n",
    "        real: : torch.Tensor\n",
    "            A batch of real images.\n",
    "        fake: torch.Tensor\n",
    "            A batch of fake images.\n",
    "        epsilon: torch.Tensor\n",
    "            A vector of the uniformly random proportions of real/fake per mixed image.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The gradient of the critic scores, with respect to the mixed image.\n",
    "    \"\"\"\n",
    "    # Mix the images together.\n",
    "    mixed_images = real * epsilon + fake * (1 - epsilon)\n",
    "\n",
    "    # Calculate the critic scores on the mixed images.\n",
    "    mixed_scores = crit(mixed_images)\n",
    "    \n",
    "    # Take the gradient of the scores with respect to the images.\n",
    "    return torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores), \n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "\n",
    "def gradient_penalty(gradient: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the gradient penalty, given a gradient.\n",
    "    Given a batch of image gradients, you calculate the magnitude of each image's gradient\n",
    "    and penalize the mean quadratic distance of each magnitude to 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        gradient: torch.Tensor\n",
    "            The gradient of the critic scores, with respect to the mixed image.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        penalty: torch.Tensor\n",
    "            The gradient penalty.\n",
    "    \"\"\"\n",
    "    # Flatten the gradients so that each row captures one image.\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "\n",
    "    # Calculate the magnitude of every row.\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    \n",
    "    # Penalize the mean squared distance of the gradient norms from 1.\n",
    "    return torch.mean((gradient_norm -1)**2)\n",
    "\n",
    "\n",
    "def get_gen_loss(crit_fake_pred: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the loss of a generator given the critic scores of the generator's fake images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    crit_fake_pred: torch.Tensor\n",
    "        The critic scores of the fake images.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        A scalar loss value for the current batch of the generator.\n",
    "    \"\"\"\n",
    "    return -1* torch.mean(crit_fake_pred)\n",
    "\n",
    "\n",
    "def get_crit_loss(crit_fake_pred: torch.Tensor, crit_real_pred: torch.Tensor,\n",
    "                  gp: torch.Tensor, c_lambda: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the loss of a critic given the critic scores for fake and real images,\n",
    "    the gradient penalty, and gradient penalty weight.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    crit_fake_pred: torch.Tensor\n",
    "        The critic scores of the fake images.\n",
    "    crit_real_pred: torch.Tensor\n",
    "        The critic scores of the real images.\n",
    "    gp: torch.Tensor\n",
    "        The unweighted gradient penalty.\n",
    "    c_lambda: float\n",
    "        The current weight of the gradient penalty\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        A scalar for the critic's loss, accounting for the relevant factors.\n",
    "    \"\"\"\n",
    "    return torch.mean(crit_fake_pred - crit_real_pred + gp * c_lambda)\n",
    "\n",
    "\n",
    "print('Finished defining functions for calculating the gradient penalty.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac0093-a925-4c4b-b6d9-6fd9dca3cae8",
   "metadata": {},
   "source": [
    "## Initialize the network\n",
    "### Description\n",
    "* Initialize the generator and the critic.\n",
    "* Initialize the loss and optimizer function.\n",
    "* Apply starting weights to the generator and critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b0db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m: object):\n",
    "    \"\"\"\n",
    "    Initialize the weights for Conv2d and ConvTranspose2d layers to the normal distribution with mean 0 and standard deviation 0.02.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m: object\n",
    "        The mean weight value.\n",
    "    \"\"\"\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "\n",
    "\n",
    "# Initialize the generator and critic.\n",
    "gen = Generator(RUN_Z_DIM + sum(RUN_LABEL_CHANNELS), RUN_HIDDEN_DIM, RUN_DROPOUT_VALUE, RUN_LEAK_VALUE).to(RUN_DEVICE)\n",
    "crit = Critic(1 + sum(RUN_LABEL_CHANNELS), RUN_HIDDEN_DIM, RUN_DROPOUT_VALUE, RUN_LEAK_VALUE).to(RUN_DEVICE)\n",
    "\n",
    "# Define the loss function.\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the optimizer for both generator and discriminator.\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=RUN_OPT_LR, betas=(RUN_OPT_BETA_1, RUN_OPT_BETA_2))\n",
    "crit_opt = torch.optim.Adam(crit.parameters(), lr=RUN_OPT_LR, betas=(RUN_OPT_BETA_1, RUN_OPT_BETA_2))\n",
    "\n",
    "# Apply the starting weights to generator and critic.\n",
    "gen = gen.apply(weights_init)\n",
    "crit = crit.apply(weights_init)\n",
    "\n",
    "print('Finished initializing the network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb3455-1fc5-4acc-99b4-7b7b70aa19b8",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "### Description\n",
    "Trains the network and uses a predefined noise vector to test the network after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404eb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_one_hot(labels: torch.Tensor, classes: torch.tensor) -> torch.Tensor:        \n",
    "    \"\"\"\n",
    "    Takes a label tensor which multiple categories.\n",
    "    Creates a one_tensor for each of these categories and combines them in the end to one tensor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: torch.Tensor of float\n",
    "        Contains the classes for multiple categories.\n",
    "    classes: torch.Tensor of int\n",
    "        Contains the number of classes for each category.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The combined one_hot tensor object.\n",
    "    \"\"\"\n",
    "    # Define a variable for the output tensor.\n",
    "    out_labels = None\n",
    "    \n",
    "    # Split the label vector in one vector for each category and then loop over each of these new vectors.\n",
    "    chunks = torch.split(labels, 1, dim=1)\n",
    "    for i in range(0, len(chunks)):\n",
    "        # Remove the redundant dimension 1.\n",
    "        reshaped_chunk = torch.reshape(chunks[i], (labels.size(0),))\n",
    "        \n",
    "        # Create the one_hot coded vector for one category.\n",
    "        one_hot_labels = torch.nn.functional.one_hot(reshaped_chunk, num_classes=classes[i])\n",
    "        \n",
    "        # Add the one_hot coded vector to the output vector.\n",
    "        if out_labels == None:\n",
    "            out_labels = one_hot_labels\n",
    "        else:\n",
    "            out_labels = torch.cat([out_labels, one_hot_labels], 1)\n",
    "    \n",
    "    return out_labels\n",
    "\n",
    "\n",
    "# Create output folder and the images folder inside the output folder.\n",
    "os.mkdir(RES_OUTPUT_FOLDER)\n",
    "os.mkdir(os.path.join(RES_OUTPUT_FOLDER, RES_IMAGE_FOLDER))\n",
    "\n",
    "# Lists for storing the losses.\n",
    "gen_loss_epoch = []\n",
    "gen_loss_step = []\n",
    "crit_loss_epoch = []\n",
    "crit_loss_step = []\n",
    "test_loss_epoch = []\n",
    "\n",
    "# Use the test labels to create a one_hot label tensor.\n",
    "test_labels = RUN_TEST_LABELS.repeat([PREP_BATCH_SIZE, 1])\n",
    "test_one_hot_labels = multi_one_hot(test_labels, RUN_LABEL_CHANNELS).to(RUN_DEVICE)\n",
    "\n",
    "# Create a noise vector, for testing and combine it with the test labels.\n",
    "test_noise = get_noise(PREP_BATCH_SIZE, RUN_Z_DIM, RUN_DEVICE)\n",
    "test_noise_and_labels = torch.cat((test_noise.float(), test_one_hot_labels.float()), 1)\n",
    "\n",
    "# Create a one_hot image tensor based on the test labels.\n",
    "test_image_one_hot_labels = test_one_hot_labels[:, :, None, None]\n",
    "test_image_one_hot_labels = test_image_one_hot_labels.repeat(1, 1, PREP_IMAGE_SIZE, PREP_IMAGE_SIZE).to(RUN_DEVICE)\n",
    "\n",
    "# Run epoch.\n",
    "for epoch in range(RUN_EPOCHS):  \n",
    "    # Set loader count and length for showing the last result of the epoch.\n",
    "    loader_count = 0\n",
    "    loader_length = len(loader_train)\n",
    "    \n",
    "    # Inside the epoch run each batch from the data loader.\n",
    "    for real, labels in tqdm(loader_train):\n",
    "        # Create variable for current batch size.\n",
    "        cur_batch_size = len(real)\n",
    "        \n",
    "        # Increase counter.\n",
    "        loader_count += 1\n",
    "\n",
    "        # Set the real image to the chosen device.\n",
    "        real = real.to(RUN_DEVICE)\n",
    "\n",
    "        # Create one_hot labels and image.       \n",
    "        one_hot_labels = multi_one_hot(labels, RUN_LABEL_CHANNELS).to(RUN_DEVICE)\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = image_one_hot_labels.repeat(1, 1, PREP_IMAGE_SIZE, PREP_IMAGE_SIZE).to(RUN_DEVICE)\n",
    "\n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(RUN_CRITIC_REPEAT):\n",
    "            # Get the noise vector.\n",
    "            crit_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, RUN_Z_DIM, device=RUN_DEVICE)\n",
    "            # Combine the noise vector with the one_hot labels.\n",
    "            noise_and_labels = torch.cat((fake_noise.float(), one_hot_labels.float()), 1)\n",
    "            \n",
    "            # Create the fake image.\n",
    "            fake = gen(noise_and_labels).to(RUN_DEVICE)                                     \n",
    "            \n",
    "            # Combine real and fake image with the one_hot image.\n",
    "            fake_image_and_labels = torch.cat((fake, image_one_hot_labels), 1)\n",
    "            real_image_and_labels = torch.cat((real, image_one_hot_labels), 1)                           \n",
    "            \n",
    "            # Send both images through the critic.\n",
    "            crit_fake_pred = crit(fake_image_and_labels.detach())\n",
    "            crit_real_pred = crit(real_image_and_labels)\n",
    "            \n",
    "            # Calculate the gradient penalty.\n",
    "            epsilon = torch.rand(cur_batch_size, 1, 1, 1, device=RUN_DEVICE, requires_grad=True)\n",
    "            gradient = get_gradient(crit, real_image_and_labels, fake_image_and_labels.detach(), epsilon)\n",
    "            gp = gradient_penalty(gradient)\n",
    "            crit_loss = get_crit_loss(crit_fake_pred, crit_real_pred, gp, RUN_CRITIC_LAMBDA)\n",
    "\n",
    "            # Keep track of the average critic loss in this batch.\n",
    "            mean_iteration_critic_loss += crit_loss.item() / RUN_CRITIC_REPEAT\n",
    "            \n",
    "            # Update the gradients.\n",
    "            crit_loss.backward(retain_graph=True)\n",
    "            \n",
    "            # Update the optimizer.\n",
    "            crit_opt.step()\n",
    "        \n",
    "        # Add the critics loss value to the list, after each step.\n",
    "        crit_loss_step += [mean_iteration_critic_loss]\n",
    "           \n",
    "        # Get the noise vector for updating the generator.\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, RUN_Z_DIM, device=RUN_DEVICE)\n",
    "        \n",
    "        # Combine the noise vector with the one_hot labels.\n",
    "        noise_and_labels_2 = torch.cat((fake_noise_2.float(), one_hot_labels.float()), 1)        \n",
    "        \n",
    "        # Create fake image for updating the generator. \n",
    "        fake_2 = gen(noise_and_labels_2).to(RUN_DEVICE)        \n",
    "        \n",
    "        # Combine the fake image with the one_hot image.\n",
    "        fake_image_and_labels_2 = torch.cat((fake_2, image_one_hot_labels), 1)\n",
    "        \n",
    "        # Calculate the prediction and update the generator.\n",
    "        crit_fake_pred_2 = crit(fake_image_and_labels_2)\n",
    "        gen_loss = get_gen_loss(crit_fake_pred_2)\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        \n",
    "        # Add the generator loss value to the list, after each step.\n",
    "        gen_loss_step += [gen_loss.item()]\n",
    "\n",
    "        # Show the generated images.\n",
    "        if loader_count == loader_length:            \n",
    "            # Add the generator and the critic loss to the lists, after each epoch.\n",
    "            crit_loss_epoch += [mean_iteration_critic_loss]\n",
    "            gen_loss_epoch += [gen_loss.item()]\n",
    "            \n",
    "            # Set the generator and the critic to evaluation mode.\n",
    "            gen.eval()\n",
    "            crit.eval()\n",
    "            \n",
    "            # Use the test_noise to create images and calculate the loss.\n",
    "            test_fake = gen(test_noise_and_labels).to(RUN_DEVICE)\n",
    "            test_fake_image_and_labels = torch.cat((test_fake, test_image_one_hot_labels), 1)\n",
    "            test_pred = crit(test_fake_image_and_labels.detach())\n",
    "            test_loss = get_gen_loss(test_pred)\n",
    "            test_loss_epoch.append(test_loss.item())\n",
    "\n",
    "            # Save the model to disk.\n",
    "            if epoch == RUN_EPOCHS - 1:\n",
    "                torch.save(gen, os.path.join(RES_OUTPUT_FOLDER, '{}model_{:04d}.p'.format(RES_MODEL_PATH, epoch)))\n",
    "            \n",
    "            # Set the generator and the critic back into training mode.\n",
    "            gen.train()\n",
    "            crit.train()\n",
    "\n",
    "            # Create a pyplot with the fake images.\n",
    "            if epoch % RUN_DISPLAY_EACH == 0:\n",
    "                print('original image')\n",
    "                show_tensor_images(np.array(test_image), [], 1, int(RES_PLOT_SIZE/RES_PLOT_COLUMNS), 0, '')\n",
    "                pred_result = test_fake.cpu().detach().numpy()\n",
    "                pred_result = pred_result * 255\n",
    "                print('fake images')\n",
    "                show_tensor_images(pred_result, [], RES_PLOT_COLUMNS, RES_PLOT_SIZE, 0,\n",
    "                                   os.path.join(\n",
    "                                       RES_OUTPUT_FOLDER,\n",
    "                                       RES_IMAGE_FOLDER ,\n",
    "                                       'image_for_epoch_{:04d}'.format(epoch)\n",
    "                                   )\n",
    "                                  )\n",
    "\n",
    "            # Print the loss values for this epoch.\n",
    "            print(f\"Epoch {epoch}, Generator loss: {gen_loss.item()}, discriminator loss: {mean_iteration_critic_loss}\")\n",
    "\n",
    "print('Finished training the network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0869d52-0165-4598-9b43-92996f8f9158",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Description\n",
    "* Show loss value in a line diagram.\n",
    "* Save the loss values to file.\n",
    "* Create a GIF file from the single PNG files.\n",
    "* Show the GIF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show loss value for each step in the training process.\n",
    "plt.plot(np.array(gen_loss_step), label='gen-loss', color='red')\n",
    "plt.plot(np.array(crit_loss_step), label='crit-loss', color='blue')\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(RES_OUTPUT_FOLDER, RES_LOSS_PLOT_TRAIN))\n",
    "plt.show()\n",
    "\n",
    "# Show all loss values after each epoch.\n",
    "plt.plot(np.array(gen_loss_epoch), label='gen-loss', color='red')\n",
    "plt.plot(np.array(crit_loss_epoch), label='crit-loss', color='blue')\n",
    "plt.plot(np.array(test_loss_epoch), label='test-loss', color='green')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(RES_OUTPUT_FOLDER, RES_LOSS_PLOT_TEST))\n",
    "plt.show()\n",
    "\n",
    "# Store data in text files.\n",
    "np.savetxt(os.path.join(RES_OUTPUT_FOLDER, RES_LOSS_DATA_CRIT), np.array(crit_loss_epoch))\n",
    "np.savetxt(os.path.join(RES_OUTPUT_FOLDER, RES_LOSS_DATA_GEN), np.array(gen_loss_epoch))\n",
    "np.savetxt(os.path.join(RES_OUTPUT_FOLDER, RES_LOSS_DATA_TEST), np.array(test_loss_epoch))\n",
    "\n",
    "# Get all the PNG filenames and sort them.\n",
    "filenames = glob.glob(os.path.join(RES_OUTPUT_FOLDER, RES_IMAGE_FOLDER, 'image*.png'))\n",
    "filenames = sorted(filenames)\n",
    "\n",
    "# Create one GIF file from all the PNG files.\n",
    "images = []\n",
    "gif_file = os.path.join(RES_OUTPUT_FOLDER, RES_GIF_FILE)\n",
    "for filename in filenames:\n",
    "    images.append(imageio.v2.imread(filename))\n",
    "imageio.mimsave(gif_file, images, fps=3)\n",
    "\n",
    "# Show the GIF file.\n",
    "Image(url=gif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72653a19-5fa1-4f93-87f6-1a5c893149e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
