{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f357f6-4f03-496f-9a85-5e3d9e68ba94",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "### Standard modules\n",
    "* glob: [Unix style pathname pattern expansion.](https://docs.python.org/3/library/glob.html?highlight=glob#module-glob)\n",
    "* gzip: [This module provides a simple interface to compress and decompress files.](https://docs.python.org/3/library/gzip.html)\n",
    "* math: [Mathematical functions.](https://docs.python.org/3/library/math.html)\n",
    "* os: [Miscellaneous operating system interfaces.](https://docs.python.org/3/library/os.html?highlight=os#module-os)\n",
    "* random: [Generate pseudo-random numbers.](https://docs.python.org/3/library/random.html?highlight=random#module-random)\n",
    "* shutil: [Offers a number of high-level operations on files and collections of files.](https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil)\n",
    "* struct: [Interpret bytes as packed binary data.](https://docs.python.org/3/library/struct.html?highlight=struct#module-struct)\n",
    "\n",
    "### Jupyter notebook modules\n",
    "* IPython: [IPython provides a rich toolkit to help you make the most of using Python interactively.](https://ipython.readthedocs.io/en/stable/)\n",
    "\n",
    "### Additional packages\n",
    "* imageio: [Provides an easy interface to read and write a wide range of image data.](https://imageio.readthedocs.io/en/stable/)\n",
    "* matplotlib: [Library for creating static, animated, and interactive visualizations.](https://matplotlib.org/stable/users/index)\n",
    "* numpy: [Library that provides a multidimensional array object, various derived objects, and an assortment of routines for fast operations on arrays.](https://numpy.org/doc/stable/)\n",
    "* torch: [An optimized tensor library for deep learning using GPUs and CPUs.](https://pytorch.org/docs/stable/index.html)\n",
    "* torchvision: [Package consists of popular datasets, model architectures, and common image transformations for computer vision.](https://pytorch.org/vision/stable/index.html)\n",
    "* tqdm : [Adds a smart progress meter to loops.](https://tqdm.github.io/)\n",
    "* wget: [Package for downloading files from web addresses.](https://pypi.org/project/wget/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python standard modules.\n",
    "import glob\n",
    "import gzip\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import struct\n",
    "\n",
    "# Jupyter notebook modules.\n",
    "from IPython.display import Image\n",
    "\n",
    "# Install additional packages.\n",
    "!pip install -qq imageio matplotlib numpy torch torchvision tqdm wget\n",
    "\n",
    "# Import the installed packages. \n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import wget\n",
    "\n",
    "print('Finished importing the packages.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18854578-88e0-43c9-b4ae-87dfbccdde5e",
   "metadata": {},
   "source": [
    "## Define arguments\n",
    "### DATA_*\n",
    "Arguments for loading the data.\n",
    "* DATA_FILE_TYPES: The file extensions of the norb dataset.\n",
    "* DATA_FOLDER: The folder where the data files are stored.\n",
    "* DATA_PREFIXES: The file prefix of the norb file names.\n",
    "* DATA_NUMBERS_FOR_MAPPING_DATA_TYPES: The magic number encodes the element type of the matrix. Note: This are only the numbers needed for the files in this project.\n",
    "* DATA_URL: Url for downloading the data files.\n",
    "\n",
    "### PREP_*\n",
    "Arguments for preparing the data.\n",
    "* PREP_BATCH_SIZE: Defines how many files are prosseced in each step.\n",
    "* PREP_CAMERA: Index of the camera (channel of the image).\n",
    "* PREP_IMAGE_SIZE: Pixel size of the images.\n",
    "* PREP_SHUFFLE_DATA: If true, the data is shuffeld.\n",
    "\n",
    "### RUN_*\n",
    "Arguments for definning and running the neural network.\n",
    "* RUN_CRITIC_REPEAT: Defines how offten the critic is used in each step.\n",
    "* RUN_DEVICE: Which device to use for running the network (cuda or cpu).\n",
    "* RUN_DROPOUT_VALUE: Probability of an element to be zeroed.\n",
    "* RUN_EPOCHS: Defines how offten the training is repeated for all data.\n",
    "* RUN_HIDDEN_DIM: The ground value for the dimensions in the hidden layers.\n",
    "* RUN_LEAK_VALUE: Controls the angle of the negative slope for the leakyRelu function.\n",
    "* RUN_OPT_BETA_1: Parameter for the Adam optimizer. The exponential decay rate for the first-moment estimates.\n",
    "* RUN_OPT_BETA_2: Parameter for the Adam optimizer. The exponential decay rate for the second-moment estimates.\n",
    "* RUN_OPT_LR: Weight of the gradient penalty\n",
    "* RUN_Z_DIM: Defines hwo many channels the noise tensor has.\n",
    "\n",
    "### RES_*\n",
    "Arguments for showing the results.\n",
    "* RES_GIF_FILE: Name and path for storing the gif file, containing the result data.\n",
    "* RES_IMAGE_AMOUNT: Hwo many images to show.\n",
    "* RES_PLOT_COLUMNS: The amount of images in one row of the plot.\n",
    "* RES_PLOT_SIZE: The size of the plots widht and height in inches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e96882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables.\n",
    "DATA_FILE_TYPES = ['info', 'cat', 'dat']\n",
    "DATA_FOLDER = \"./decrompressed/\"\n",
    "DATA_PREFIXES = {\n",
    "    'train': 'smallnorb-5x46789x9x18x6x2x96x96-training-',\n",
    "    'test': 'smallnorb-5x01235x9x18x6x2x96x96-testing-',\n",
    "}\n",
    "DATA_NUMBERS_FOR_MAPPING_DATA_TYPES = {\n",
    "    '1e3d4c55': np.uint8,\n",
    "    '1e3d4c54': np.int32,\n",
    "}\n",
    "DATA_URL = 'https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/'\n",
    "\n",
    "PREP_BATCH_SIZE = 32\n",
    "PREP_CAMERA = 0\n",
    "PREP_IMAGE_SIZE = 96\n",
    "PREP_SHUFFLE_DATA = True\n",
    "\n",
    "RUN_CRITIC_REPEAT = 3\n",
    "RUN_CRITIC_LAMBDA = 10.0\n",
    "RUN_DEVICE = 'cuda'\n",
    "RUN_DROPOUT_VALUE = 0.1\n",
    "RUN_EPOCHS = 3\n",
    "RUN_HIDDEN_DIM = 32\n",
    "RUN_LEAK_VALUE = 0.01\n",
    "RUN_OPT_BETA_1 = 0.5 \n",
    "RUN_OPT_BETA_2 = 0.999\n",
    "RUN_OPT_LR = 0.0002\n",
    "RUN_Z_DIM = 100\n",
    "\n",
    "RES_GIF_FILE = 'norb_dcgan.gif'\n",
    "RES_IMAGE_AMOUNT = 9\n",
    "RES_PLOT_COLUMNS = 3\n",
    "RES_PLOT_SIZE = 50\n",
    "\n",
    "print('Finished setting the arguments.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2d3d0-7c35-4138-be9d-bd0bda889bab",
   "metadata": {},
   "source": [
    "## Load files\n",
    "### Description\n",
    "Download the files and convert the binary data to tensor objects. Afterwards show some examples.\n",
    "\n",
    "### Functions\n",
    "* download_and_unzip: Downloads and unzips a file.\n",
    "* get_int_from_file: Helper function for reading int from binary file.\n",
    "* load_norb_data: Load the norb data from binary files and convert it to images.\n",
    "* show_tensor_images: Shows images using pyplot from the matplotlib package. Also prints some information about the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ddd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(file_name: str, file_extension: str, dst_folder: str, url: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads and unzips a file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name: str\n",
    "         The basename of the compressed file (without the extension for the compressed version).\n",
    "    file_extension: str\n",
    "        The file extension for the compressed version.\n",
    "    dst_folder: str\n",
    "        Destination folder for the files.\n",
    "    url: str\n",
    "        Source url for the file, without the filename.\n",
    "    \"\"\"\n",
    "    # Build file and zip path.\n",
    "    file_path = os.path.join(dst_folder, file_name)\n",
    "    gz_name = file_name + '.gz'\n",
    "\n",
    "    # Check if the data folder already exists, if not create the folder.\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.mkdir(dst_folder)\n",
    "\n",
    "    # Check if this file already exists.\n",
    "    if not os.path.exists(file_path):\n",
    "        # Download the file.\n",
    "        wget.download(url + gz_name , gz_name)\n",
    "\n",
    "        # Decrompress the file and move it to the folder.\n",
    "        with gzip.open(gz_name, 'rb') as f_in:\n",
    "            with open(file_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        # Delete the compressed version afterwards.\n",
    "        os.remove(gz_name)\n",
    "\n",
    "def get_int_from_file(f: object) -> int:\n",
    "    \"\"\"\n",
    "    Helper function for reading int from binary file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: file-object\n",
    "        The data file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The content of the file as integer.\n",
    "    \"\"\"\n",
    "    num, = struct.unpack('i', f.read(4))\n",
    "    return num\n",
    "\n",
    "\n",
    "def load_norb_data(file_folder: str, file_prefix: object, file_types: list, map_data_types: object) -> object: \n",
    "    \"\"\"\n",
    "    Load the norb data from binary files and convert it to images.\n",
    "    \n",
    "    Paramaters\n",
    "    ----------\n",
    "    map_data_types\n",
    "    file_folder: str\n",
    "        The folder where the data files are stored.\n",
    "    file_prefix: object of str\n",
    "        The file prefix of the norb file names.\n",
    "    file_types: list of str\n",
    "        The file extensions of the norb dataset.\n",
    "    map_data_types: object of numpy.dtype\n",
    "        The magic number encodes the element type of the matrix.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    object\n",
    "        Images of the norb dataset.\n",
    "    \"\"\"\n",
    "    # Define return object.\n",
    "    loaded_data = {}\n",
    "    \n",
    "    # Loop over each file.\n",
    "    for dataset, prefix in file_prefix.items():\n",
    "        for filetype in file_types:\n",
    "            # Set up the file name and path for reading the files.\n",
    "            filename = prefix + filetype + \".mat\"\n",
    "            file_loc = os.path.join(file_folder, filename)\n",
    "\n",
    "            with open( file_loc, 'rb') as f:\n",
    "                # Read the magic_num, convert it to hexadecimal and look up the data_type.\n",
    "                raw_magic_num = get_int_from_file(f)\n",
    "                magic_num = format(raw_magic_num, '02x')\n",
    "                data_type = map_data_types[magic_num]\n",
    "\n",
    "                # Read how many dimensions to expect.\n",
    "                ndim = get_int_from_file(f)\n",
    "\n",
    "                # Read at least 3 ints, or however many ndim there are.\n",
    "                shape = [\n",
    "                    get_int_from_file(f)\n",
    "                    for i in range(max(ndim, 3))\n",
    "                ]   \n",
    "\n",
    "                # But in case ndims < 3, take at most n_dim elements.\n",
    "                shape = shape[:ndim]\n",
    "\n",
    "                # Now load the actual data.\n",
    "                loaded_data[(dataset, filetype)] = np.fromfile(\n",
    "                    f, \n",
    "                    dtype=data_type, \n",
    "                    count=np.prod(shape)\n",
    "                ).reshape(shape)\n",
    "    \n",
    "    return loaded_data        \n",
    "\n",
    "\n",
    "def show_tensor_images(image: np.array, infos: list, columns: int, size: int, channel: int =-1, file_path: str ='') -> None:\n",
    "    \"\"\"\n",
    "    Shows images using pyplot from the matplotlib package. Also prints some information about the images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.array\n",
    "        The image numpy array.\n",
    "    infos: list of str\n",
    "        Contains some information about the images.\n",
    "    columns: int\n",
    "        The amount of columns for the plot\n",
    "    size: int\n",
    "        The size of the plots widht and height in inches.\n",
    "    channel: int, optional\n",
    "        If -1 all channels are showen as rgb image. If not -1 only this specific channel is shown as grayscale image.\n",
    "    file_path: str, optional\n",
    "        If '' the plots are not saved as gif. If not '' the contant of file_path is used to save the images as png.\n",
    "    \"\"\"\n",
    "    # Get the image amount and define the amount of rows for the plot.\n",
    "    image_length = len(image)\n",
    "    rows = math.ceil(image_length / columns)\n",
    "    \n",
    "    # Set the size for each image in the plot.\n",
    "    fig = plt.figure(figsize=(size,size)) \n",
    "    \n",
    "    # Loop over each image and add it to the plot.\n",
    "    for i in range(0, image_length):\n",
    "        plt.subplot(rows, columns, i+1)\n",
    "        \n",
    "        if channel == -1:\n",
    "            plt.imshow(images[i], cmap=\"rgb\")\n",
    "        else:\n",
    "            plt.imshow(image[i][channel], cmap=\"gray\")\n",
    "            \n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Save the file, if file_path is set.\n",
    "    if file_path != '':\n",
    "        plt.savefig('{}.png'.format(file_path))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print the content of the infos list.\n",
    "    for j in range(0, len(infos)):\n",
    "        print(f'{j+1}: {infos[j]}')\n",
    "\n",
    "\n",
    "# Loop over each file prefix and file type and download the files.\n",
    "for prefix in DATA_PREFIXES:\n",
    "    for t in DATA_FILE_TYPES:   \n",
    "        download_and_unzip(DATA_PREFIXES[prefix] + t + '.mat', '.gz', DATA_FOLDER, DATA_URL)\n",
    "                \n",
    "# Load the data files.\n",
    "loaded_data = load_norb_data(DATA_FOLDER, DATA_PREFIXES, DATA_FILE_TYPES, DATA_NUMBERS_FOR_MAPPING_DATA_TYPES)\n",
    "\n",
    "# Show some random original images.\n",
    "idx = np.random.randint( loaded_data[('train', 'cat')].shape[0], size=RES_IMAGE_AMOUNT)\n",
    "\n",
    "# Collect the information from the files for showing some examples.\n",
    "infos = []\n",
    "images = []\n",
    "for i in idx:\n",
    "    # Print The information for this file. Based on cat and info file.\n",
    "    info_text = str(loaded_data[('train', 'cat')][i]) + ' ' + str(loaded_data[('train', 'info')][i])\n",
    "    infos.append(info_text)\n",
    "    \n",
    "    # Get the image data from the dat file.\n",
    "    images.append(loaded_data[('train', 'dat')][i])\n",
    "    \n",
    "# Show image.\n",
    "show_tensor_images(np.array(images), infos, RES_PLOT_COLUMNS, RES_PLOT_SIZE, 0, '')\n",
    "\n",
    "print('Finished loading files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcba63-a0f5-41ca-9b88-be6b35efd639",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "### Description\n",
    "Here the data are preproccesed (normalization, resizing etc.) and a data loader is created, that can be used for training the model.\n",
    "\n",
    "### Transformation steps\n",
    "* Selecting a specific camera (tensor channel).\n",
    "* Converting the tensor values from a range of 0 to 255 to a range of 0 to 1.\n",
    "* Insure that all images have the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc61166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the content from the dat files.\n",
    "images_train = torch.from_numpy(loaded_data[('train', 'dat')])\n",
    "images_test  = torch.from_numpy(loaded_data[('test', 'dat')])\n",
    "\n",
    "# Load the content from the cat files.\n",
    "category_train = torch.from_numpy(loaded_data[('train', 'cat')])\n",
    "category_test  = torch.from_numpy(loaded_data[('test', 'cat')])\n",
    "\n",
    "# Define transformation for the data.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x[PREP_CAMERA]),\n",
    "    transforms.Lambda(lambda x: (x - 127.5) / 127.5),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(PREP_IMAGE_SIZE),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Transform the training data.\n",
    "data_train = torch.empty([images_train.size(0), 1, PREP_IMAGE_SIZE, PREP_IMAGE_SIZE])\n",
    "for i in range(0, images_train.size(0)):\n",
    "    data_train[i] = transform(images_train[i])\n",
    "\n",
    "# Transform the test data.\n",
    "data_test = torch.empty([images_test.size(0), 1, PREP_IMAGE_SIZE, PREP_IMAGE_SIZE])\n",
    "for i in range(0, images_test.size(0)):\n",
    "    data_test[i] = transform(images_test[i])\n",
    "    \n",
    "# Create data sets for training and test files.\n",
    "data_train = torch.utils.data.TensorDataset(data_train, category_train)\n",
    "data_test = torch.utils.data.TensorDataset(data_test, category_train)\n",
    "\n",
    "# Merge both datasets.\n",
    "merged_data = torch.utils.data.ConcatDataset([data_train, data_test])\n",
    "\n",
    "# Create a dataloader for the data.\n",
    "loader_train = torch.utils.data.DataLoader(merged_data, batch_size=PREP_BATCH_SIZE, shuffle=PREP_SHUFFLE_DATA)\n",
    "\n",
    "print('Finished preproccessing the data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48a584-84e5-43e6-94f5-473677f128b8",
   "metadata": {},
   "source": [
    "## Define the network\n",
    "### Description\n",
    "Defines a function for creating the noise vector and the classes for genrator and critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_samples: int, z_dim: int, device: str ='cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create a noise vector with dimensions (n_samples, z_dim)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples: int\n",
    "        The amount of samples.\n",
    "    z_dim: int\n",
    "        The amount of dimensions/channels.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.tensor\n",
    "        Noise vector.\n",
    "    \"\"\"\n",
    "    return torch.randn(n_samples, z_dim, device=device)\n",
    "\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    \"\"\" \n",
    "    The generator class for producing fake images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z_dim: int\n",
    "        The dimensions/channels of the noise vector.\n",
    "    hidden_dim: int\n",
    "        The ground value for the dimensions in the hidden layers.\n",
    "    dropout_value: float, optional\n",
    "        Probability of an element to be zeroed.\n",
    "    leak_value: float, optional\n",
    "        Controls the angle of the negative slope.\n",
    "    \"\"\"\n",
    "    def __init__(self, z_dim: int, hidden_dim: int, dropout_value: float =0.5, leak_value: float = 0.01) -> None:\n",
    "        \"\"\"\n",
    "        Initialization function for the gernator. \n",
    "        Defines how many network blocks are used and which are used for each block.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.gen = torch.nn.Sequential(\n",
    "            self.gen_block(z_dim, hidden_dim, 3, 1, dropout_value, leak_value),\n",
    "            self.gen_block(hidden_dim, hidden_dim*2, 3, 2, dropout_value, leak_value),\n",
    "            self.gen_block(hidden_dim*2, hidden_dim*4, 5, 1, dropout_value, leak_value),\n",
    "            self.gen_block(hidden_dim*4, hidden_dim*8, 5, 2, dropout_value, leak_value),\n",
    "            self.gen_block(hidden_dim*8, hidden_dim*4, 7, 1, dropout_value, leak_value),\n",
    "            self.gen_block(hidden_dim*4, hidden_dim, 7, 2, dropout_value, leak_value),\n",
    "            self.gen_block(hidden_dim, hidden_dim, 12, 1, dropout_value, leak_value),\n",
    "            self.gen_block(hidden_dim, 1, 19, 1, dropout_value, leak_value, final_layer=True)          \n",
    "        )\n",
    "\n",
    "    def gen_block(self, input_channels: int, output_channels: int, \n",
    "                  kernel_size: int, stride: int, dropout_value: float, \n",
    "                  leak_value: float, final_layer: bool =False) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Defines one block of the network. Each block contains one or more type of layer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_channels: int\n",
    "            Number of channels in the input image.\n",
    "        output_channels: int\n",
    "            Number of channels produced by the convolution.\n",
    "        kernel_size: int\n",
    "            The size of the filters that are used.\n",
    "        stride: int\n",
    "            The amount of steps taken, moving from one frame to another the next frame.\n",
    "        dropout_value: float\n",
    "            Probability of an element to be zeroed.\n",
    "        leak_value: float\n",
    "            Controls the angle of the negative slope.\n",
    "        final_layer: bool\n",
    "            Flag for differentating between the final layer and all other layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.nn.Sequential\n",
    "            A combination of different layers for the generator.\n",
    "        \"\"\"\n",
    "        if not final_layer:\n",
    "            # Define the block for not final layer.\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                torch.nn.InstanceNorm2d(output_channels),\n",
    "                torch.nn.LeakyReLU(leak_value, inplace=True),\n",
    "                torch.nn.Dropout(dropout_value)\n",
    "            )\n",
    "        else:\n",
    "            # Define the block for the final layer.\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                torch.nn.BatchNorm2d(output_channels),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "\n",
    "    def forward(self, noise: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Function for completing a forward pass of the generator.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        noise: torch.Tensor\n",
    "            A noise vector.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            An image.\n",
    "        \"\"\"\n",
    "        x = noise.view(noise.size(0), noise.size(1), 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "class Critic(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The critic class defining hwo real a fake image is.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_channel: int\n",
    "        The channels of the image.\n",
    "    hidden_dim: int\n",
    "        The ground value for the dimensions in the hidden layers.\n",
    "    dropout_value: float, optional\n",
    "        Probability of an element to be zeroed.\n",
    "    leak_value: float, optional\n",
    "        Controls the angle of the negative slope.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, img_channel: int, hidden_dim: int, dropout_value: float =0.5, leak_value: float = 0.01) -> None:\n",
    "        super(Critic, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialization function for the critic. \n",
    "        Defines how many network blocks are used and which are used for each block.\n",
    "        \"\"\"\n",
    "        self.crit = torch.nn.Sequential(\n",
    "            self.crit_block(img_channel, hidden_dim, 19, 1, dropout_value, leak_value),\n",
    "            self.crit_block(hidden_dim, hidden_dim*2, 12, 1, dropout_value, leak_value),\n",
    "            self.crit_block(hidden_dim*2, hidden_dim*4, 7, 2, dropout_value, leak_value),\n",
    "            self.crit_block(hidden_dim*4, hidden_dim*8, 7, 1, dropout_value, leak_value),\n",
    "            self.crit_block(hidden_dim*8, hidden_dim*4, 5, 2, dropout_value, leak_value),\n",
    "            self.crit_block(hidden_dim*4, hidden_dim, 5, 1, dropout_value, leak_value),\n",
    "            self.crit_block(hidden_dim, hidden_dim, 3, 2, dropout_value, leak_value),\n",
    "            self.crit_block(hidden_dim, 1, 3, 1, dropout_value, leak_value, final_layer=True)  \n",
    "        )\n",
    "        \n",
    "    def crit_block(self, input_channels: int, output_channels: int,\n",
    "                   kernel_size: int, stride: int, dropout_value: float,\n",
    "                   leak_value: float, final_layer=False) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Defines one block of the network. Each block contains one or more type of layer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_channels: int\n",
    "            Number of channels in the input image.\n",
    "        output_channels: int\n",
    "            Number of channels produced by the convolution.\n",
    "        kernel_size: int\n",
    "            The size of the filters that are used.\n",
    "        stride: int\n",
    "            The amount of steps taken, moving from one frame to another the next frame.\n",
    "        dropout_value: float\n",
    "            Probability of an element to be zeroed.\n",
    "        leak_value: float\n",
    "            Controls the angle of the negative slope.\n",
    "        final_layer: bool\n",
    "            Flag for differentating between the final layer and all other layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.nn.Sequential\n",
    "            A combination of different layers for the generator.\n",
    "        \"\"\"\n",
    "        if not final_layer:\n",
    "            # Define the block for not final alyer.\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                torch.nn.InstanceNorm2d(output_channels),\n",
    "                torch.nn.LeakyReLU(leak_value, inplace=True),\n",
    "                torch.nn.Dropout(dropout_value)\n",
    "            )\n",
    "        else:\n",
    "            # Define the block for the final alyer.\n",
    "            return torch.nn.Sequential( \n",
    "                torch.nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "            )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Function for completing a forward pass of the critic.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image: torch.Tensor\n",
    "            A image tensor with dimension (im_chan).\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            A 1-dimension tensor representing fake/real.\n",
    "        \"\"\"\n",
    "        crit_pred = self.crit(image)\n",
    "        return crit_pred.view(len(crit_pred), -1)\n",
    "\n",
    "\n",
    "print('Finished defining noise function, gernator and critic.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95b1ee-ded8-43d1-b2e2-7b3fb6c531e5",
   "metadata": {},
   "source": [
    "## Gradient Penalty\n",
    "### Description\n",
    "This part contains functions for calculating the gradient penalty.\n",
    "### Functions\n",
    "* get_gradient: Return the gradient of the critic's scores with respect to mixes of real and fake images.\n",
    "* gradient_penalty: Return the gradient penalty, given a gradient. Given a batch of image gradients, you calculate the magnitude of each image's gradient and penalize the mean quadratic distance of each magnitude to 1.\n",
    "* get_gen_loss: Return the loss of a generator given the critic's scores of the generator's fake images.\n",
    "* get_crit_loss: Return the loss of a critic given the critic's scores for fake and real images, the gradient penalty, and gradient penalty weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee1ad2-dbc4-4319-9c91-6c57a9316cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(crit: Critic, real: torch.Tensor, fake: torch.Tensor, epsilon: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the gradient of the critic's scores with respect to mixes of real and fake images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        crit: Critic\n",
    "            The critic model.\n",
    "        real: : torch.Tensor\n",
    "            A batch of real images.\n",
    "        fake: torch.Tensor\n",
    "            A batch of fake images.\n",
    "        epsilon: torch.Tensor\n",
    "            A vector of the uniformly random proportions of real/fake per mixed image.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The gradient of the critic's scores, with respect to the mixed image.\n",
    "    \"\"\"\n",
    "    # Mix the images together.\n",
    "    mixed_images = real * epsilon + fake * (1 - epsilon)\n",
    "\n",
    "    # Calculate the critic's scores on the mixed images\n",
    "    mixed_scores = crit(mixed_images)\n",
    "    \n",
    "    # Take the gradient of the scores with respect to the images.\n",
    "    return torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores), \n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "\n",
    "def gradient_penalty(gradient: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the gradient penalty, given a gradient.\n",
    "    Given a batch of image gradients, you calculate the magnitude of each image's gradient\n",
    "    and penalize the mean quadratic distance of each magnitude to 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        gradient: torch.Tensor\n",
    "            The gradient of the critic's scores, with respect to the mixed image.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        penalty: torch.Tensor\n",
    "            The gradient penalty.\n",
    "    \"\"\"\n",
    "    # Flatten the gradients so that each row captures one image.\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "\n",
    "    # Calculate the magnitude of every row.\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    \n",
    "    # Penalize the mean squared distance of the gradient norms from 1.\n",
    "    return torch.mean((gradient_norm -1)**2)\n",
    "\n",
    "\n",
    "def get_gen_loss(crit_fake_pred: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the loss of a generator given the critic's scores of the generator's fake images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    crit_fake_pred: torch.Tensor\n",
    "        The critic's scores of the fake images.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        A scalar loss value for the current batch of the generator.\n",
    "    \"\"\"\n",
    "    return -1* torch.mean(crit_fake_pred)\n",
    "\n",
    "\n",
    "def get_crit_loss(crit_fake_pred: torch.Tensor, crit_real_pred: torch.Tensor,\n",
    "                  gp: torch.Tensor, c_lambda: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the loss of a critic given the critic's scores for fake and real images,\n",
    "    the gradient penalty, and gradient penalty weight.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    crit_fake_pred: torch.Tensor\n",
    "        The critic's scores of the fake images.\n",
    "    crit_real_pred: torch.Tensor\n",
    "        The critic's scores of the real images.\n",
    "    gp: torch.Tensor\n",
    "        The unweighted gradient penalty.\n",
    "    c_lambda: float\n",
    "        The current weight of the gradient penalty\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        A scalar for the critic's loss, accounting for the relevant factors.\n",
    "    \"\"\"\n",
    "    return torch.mean(crit_fake_pred - crit_real_pred + gp * c_lambda)\n",
    "\n",
    "\n",
    "print('Finished defining functions for calculating the Wasserstein-Loss.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac0093-a925-4c4b-b6d9-6fd9dca3cae8",
   "metadata": {},
   "source": [
    "## Initialize the network\n",
    "### Description\n",
    "* Initialize the generator and the critic.\n",
    "* Initialize the loss and optimizer function.\n",
    "* Apply starting weights to generator and critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b0db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m: object) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Initialize the weights to the normal distribution with mean 0 and standard deviation 0.02.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m: object\n",
    "        The mean weight value.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Return the recommended gain value for the given nonlinearity function. \n",
    "    \"\"\"\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "# Initialize the generator and critic.\n",
    "gen = Generator(RUN_Z_DIM, RUN_HIDDEN_DIM, RUN_DROPOUT_VALUE, RUN_LEAK_VALUE).to(RUN_DEVICE)\n",
    "crit = Critic(1, RUN_HIDDEN_DIM, RUN_DROPOUT_VALUE, RUN_LEAK_VALUE).to(RUN_DEVICE)\n",
    "\n",
    "# Define the loss function.\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the optimizer for generator and discriminator.\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=RUN_OPT_LR, betas=(RUN_OPT_BETA_1, RUN_OPT_BETA_2))\n",
    "crit_opt = torch.optim.Adam(crit.parameters(), lr=RUN_OPT_LR, betas=(RUN_OPT_BETA_1, RUN_OPT_BETA_2))\n",
    "\n",
    "# Apply the starting weights to generator and critic.\n",
    "gen = gen.apply(weights_init)\n",
    "crit = crit.apply(weights_init)\n",
    "\n",
    "print('Finished initializing the network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb3455-1fc5-4acc-99b4-7b7b70aa19b8",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "### Description\n",
    "Trains the network and uses an predefined noise vector to test the network after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404eb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for storing the losses.\n",
    "gen_loss_list = []\n",
    "crit_loss_list = []\n",
    "\n",
    "# Define a test noise to better show the training progress.\n",
    "test_noise = get_noise(PREP_BATCH_SIZE, RUN_Z_DIM, RUN_DEVICE)\n",
    "\n",
    "# Run epoch.\n",
    "for epoch in range(RUN_EPOCHS):  \n",
    "    # Set loader count and length for showing the last result of the epoch.\n",
    "    loader_count = 0\n",
    "    loader_length = len(loader_train)\n",
    "    \n",
    "    # Inside the epoch run each batch from the dataloader.\n",
    "    for real, _ in tqdm(loader_train):\n",
    "        # Increase counter.\n",
    "        loader_count += 1\n",
    "        \n",
    "        # Set real image to choosen device.\n",
    "        real = real.to(RUN_DEVICE)\n",
    "\n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(RUN_CRITIC_REPEAT):\n",
    "            # Update critic.\n",
    "            crit_opt.zero_grad()\n",
    "            fake_noise = get_noise(len(real), RUN_Z_DIM, device=RUN_DEVICE)\n",
    "            fake = gen(fake_noise)\n",
    "            crit_fake_pred = crit(fake.detach())\n",
    "            crit_real_pred = crit(real)\n",
    "            \n",
    "            # Calculate the gradient penalty.\n",
    "            epsilon = torch.rand(len(real), 1, 1, 1, device=RUN_DEVICE, requires_grad=True)\n",
    "            gradient = get_gradient(crit, real, fake.detach(), epsilon)\n",
    "            gp = gradient_penalty(gradient)\n",
    "            crit_loss = get_crit_loss(crit_fake_pred, crit_real_pred, gp, RUN_CRITIC_LAMBDA)\n",
    "\n",
    "            # Keep track of the average critic loss in this batch.\n",
    "            mean_iteration_critic_loss += crit_loss.item() / RUN_CRITIC_REPEAT\n",
    "            \n",
    "            # Update gradients.\n",
    "            crit_loss.backward(retain_graph=True)\n",
    "            \n",
    "            # Update optimizer.\n",
    "            crit_opt.step()\n",
    "           \n",
    "        # Update generator.\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(len(real), RUN_Z_DIM, device=RUN_DEVICE)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        crit_fake_pred = crit(fake_2)\n",
    "        gen_loss = criterion(crit_fake_pred, torch.ones_like(crit_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Show the generated images.\n",
    "        if loader_count == loader_length:            \n",
    "            # Add the loss values to the list.\n",
    "            gen_loss_value = gen_loss.item()\n",
    "            gen_loss_list.append(gen_loss_value)\n",
    "            crit_loss_list.append(mean_iteration_critic_loss)\n",
    "\n",
    "            # Set the generator to evaluation mode and create a image based on the test noise.\n",
    "            gen.eval()\n",
    "            predictions = gen(test_noise)\n",
    "\n",
    "            # Set the generator back to training mode.\n",
    "            gen.train()\n",
    "\n",
    "            # Create a pyplot with the fake images.\n",
    "            pred_result = predictions.cpu().detach().numpy()\n",
    "            pred_result = pred_result * 127.5 + 127.5\n",
    "            show_tensor_images(pred_result, [], RES_PLOT_COLUMNS, RES_PLOT_SIZE, 0, 'image_for_epoch_{:04d}'.format(epoch))\n",
    "\n",
    "            # Print the loss values for this epoch.\n",
    "            print(f\"Epoch {epoch}, Generator loss: {gen_loss_value}, discriminator loss: {mean_iteration_critic_loss}\")\n",
    "\n",
    "print('Finished training the network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0869d52-0165-4598-9b43-92996f8f9158",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Description\n",
    "* Show loss value in a line diagram.\n",
    "* Create a gif file from the single png files.\n",
    "* Show the gif file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show loss value in a line diagram.\n",
    "plt.plot(np.array(gen_loss_list), label='gen-loss')\n",
    "plt.plot(np.array(crit_loss_list), label='disc-loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create a gif file from the single png files.\n",
    "with imageio.get_writer(RES_GIF_FILE, mode='I') as writer:\n",
    "  filenames = glob.glob('*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**0.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n",
    "print('Finished showing results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4e6b3-18dc-4b65-8375-c0488e3f273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! This line needs to be in an extra cell. !!!\n",
    "# Show the gif file.\n",
    "Image(url=RES_GIF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719b79f-18cc-422d-9eab-402351ca6b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
